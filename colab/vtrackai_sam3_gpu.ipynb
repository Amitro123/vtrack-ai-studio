{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP066JgO7Onb"
      },
      "source": [
        "# ğŸš€ VTrackAI Studio - GPU Backend (SAM3)\n",
        "\n",
        "**Connect local frontend to Colab GPU for real-time SAM3 video tracking!**\n",
        "\n",
        "**Requirements:**\n",
        "- Colab **T4 GPU** runtime\n",
        "- Hugging Face token (**Read** access to `facebook/sam3`)\n",
        "\n",
        "**Steps:**\n",
        "1. Runtime â†’ Change runtime type â†’ **T4 GPU**\n",
        "2. ğŸ”‘ Sidebar â†’ Secrets â†’ Add `HF_TOKEN`\n",
        "3. **Runtime â†’ Restart session** â†’ **Run all** (Ctrl+F9)\n",
        "4. Copy **Cloudflare URL** â†’ `VITE_API_URL=<url> npm run dev`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mOA7HdC7Ond"
      },
      "source": [
        "## 1. GPU Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRgU7QMr7One"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(f\"ğŸ”¥ CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"ğŸ® GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"ğŸ“Š VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"âš ï¸ Runtime â†’ Change runtime type â†’ T4 GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMQhgf8c7Onf"
      },
      "source": [
        "## 2. Install Dependencies + Clean Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6aCEOAH7Ong"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/sam3 /content/vtrack-ai-studio\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install -q fastapi uvicorn[standard] python-multipart opencv-python librosa huggingface_hub\n",
        "!pip install -q cloudflared nest-asyncio\n",
        "print(\"âœ… Dependencies ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je8VyMtO7Ong"
      },
      "source": [
        "## 3. SAM3 + VTrackAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTaM_LdF7Onh"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/facebookresearch/sam3\n",
        "!pip install -e ./sam3 --quiet\n",
        "!git clone https://github.com/Amitro123/vtrack-ai-studio\n",
        "%cd /content/vtrack-ai-studio/backend\n",
        "!pip install -r requirements.txt --quiet\n",
        "print(\"âœ… SAM3 + VTrackAI ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP0ue4xz7Oni"
      },
      "source": [
        "## 4. HF Auto-Login + SAM3 Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lE5SpA9b7UgL"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "login(token=userdata.get('HF_TOKEN'))\n",
        "print('âœ… HF logged in from Secrets')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsgFhZzY7Onj"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.makedirs(\"checkpoints/sam3\", exist_ok=True)\n",
        "\n",
        "# Download REAL SAM3 checkpoint (3.5GB)\n",
        "checkpoint_path = hf_hub_download(\n",
        "    repo_id=\"facebook/sam3\",\n",
        "    filename=\"sam3.pt\",\n",
        "    local_dir=\"./checkpoints/sam3\",\n",
        "    token=userdata.get('HF_TOKEN')\n",
        ")\n",
        "print(f\"âœ… SAM3 checkpoint: {checkpoint_path}\")\n",
        "print(f\"ğŸ“ Size: {os.path.getsize(checkpoint_path)/1e9:.1f} GB\")\n",
        "\n",
        "# Create symlinks for backend compatibility\n",
        "sam3_pt = \"./checkpoints/sam3/sam3.pt\"\n",
        "os.symlink(sam3_pt, \"./checkpoints/sam3/sam3_hiera_large.pt\")\n",
        "os.makedirs(\"./checkpoints/sam3/checkpoints\", exist_ok=True)\n",
        "os.symlink(sam3_pt, \"./checkpoints/sam3/checkpoints/sam3_hiera_tiny.pt\")\n",
        "print(\"âœ… Symlinks ready for backend\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbqUlUah7Onk"
      },
      "source": [
        "## 5. ğŸš€ Launch GPU Backend + Cloudflare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFqUBVx47Onl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/vtrack-ai-studio/backend')\n",
        "print(f\"âœ… Backend dir: {os.getcwd()}\")\n",
        "\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "import requests\n",
        "import time\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Kill old processes\n",
        "!pkill -f uvicorn || true\n",
        "!pkill cloudflared || true\n",
        "time.sleep(3)\n",
        "\n",
        "# Start backend\n",
        "print(\"ğŸš€ Starting FastAPI...\")\n",
        "uvicorn.run(\"server:app\", host=\"0.0.0.0\", port=8000, log_level=\"info\", reload=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "health-test"
      },
      "source": [
        "## ğŸ” Health Check + Cloudflare (Run this after backend starts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "health-check"
      },
      "outputs": [],
      "source": [
        "# Health check\n",
        "import requests\n",
        "r = requests.get(\"http://localhost:8000/api/health\", timeout=5)\n",
        "health = r.json()\n",
        "print(\"âœ… Health:\", health)\n",
        "\n",
        "# Cloudflare tunnel\n",
        "print(\"\\nâ³ Starting Cloudflare tunnel...\")\n",
        "!nohup cloudflared tunnel --url http://localhost:8000 > cloudflared.log 2>&1 &\n",
        "time.sleep(8)\n",
        "\n",
        "# Get URL\n",
        "!grep -o 'https://[^ ]*\\.trycloudflare\\.com' cloudflared.log || echo \"ğŸ” Check output above ğŸ‘†\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ‰ VTrackAI GPU Backend LIVE!\")\n",
        "print(f\"ğŸ‘‰ VITE_API_URL=https://xxx.trycloudflare.com npm run dev
