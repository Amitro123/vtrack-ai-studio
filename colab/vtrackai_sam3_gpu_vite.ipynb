{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Setup â€“ GPU + repos + SAM3 checkpoint\n",
                "import torch, os\n",
                "print(f\"ðŸ”¥ CUDA: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"ðŸŽ® GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"ðŸ“Š VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
                "else:\n",
                "    print(\"âš ï¸ Runtime â†’ Change runtime type â†’ GPU (T4)\")\n",
                "\n",
                "!rm -rf /content/sam3 /content/vtrack-ai-studio\n",
                "\n",
                "# Core deps\n",
                "!pip install -q torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
                "!pip install -q fastapi uvicorn[standard] python-multipart huggingface_hub\n",
                "\n",
                "# Node 18 via nvm (×œ× ×“×¨×š apt)\n",
                "!curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash\n",
                "import subprocess, textwrap\n",
                "bash_cmd = textwrap.dedent(\"\"\"\n",
                "  export NVM_DIR=\"$HOME/.nvm\"\n",
                "  [ -s \"$NVM_DIR/nvm.sh\" ] && . \"$NVM_DIR/nvm.sh\"\n",
                "  nvm install 18\n",
                "  nvm alias default 18\n",
                "  nvm use 18\n",
                "  node -v\n",
                "  npm -v\n",
                "\"\"\")\n",
                "print(subprocess.run([\"bash\", \"-lc\", bash_cmd], capture_output=True, text=True).stdout)\n",
                "\n",
                "# Clone repos\n",
                "!git clone https://github.com/facebookresearch/sam3\n",
                "!pip install -e ./sam3 -q\n",
                "\n",
                "!git clone https://github.com/Amitro123/vtrack-ai-studio\n",
                "%cd /content/vtrack-ai-studio/backend\n",
                "!pip install -r requirements.txt -q\n",
                "\n",
                "# HF login + SAM3 checkpoint\n",
                "from google.colab import userdata\n",
                "from huggingface_hub import login, hf_hub_download\n",
                "\n",
                "HF_TOKEN = userdata.get(\"HF_TOKEN\")\n",
                "login(token=HF_TOKEN)\n",
                "\n",
                "os.makedirs(\"checkpoints/sam3\", exist_ok=True)\n",
                "checkpoint_path = hf_hub_download(\n",
                "    repo_id=\"facebook/sam3\",\n",
                "    filename=\"sam3.pt\",\n",
                "    local_dir=\"./checkpoints/sam3\",\n",
                "    token=HF_TOKEN,\n",
                ")\n",
                "print(f\"âœ… SAM3 checkpoint: {checkpoint_path}\")\n",
                "\n",
                "sam3_pt = \"checkpoints/sam3/sam3.pt\"\n",
                "os.makedirs(\"checkpoints/sam3/checkpoints\", exist_ok=True)\n",
                "\n",
                "for dst in [\n",
                "    \"checkpoints/sam3/sam3_hiera_large.pt\",\n",
                "    \"checkpoints/sam3/checkpoints/sam3_hiera_tiny.pt\",\n",
                "]:\n",
                "    try:\n",
                "        if os.path.islink(dst) or os.path.exists(dst):\n",
                "            os.remove(dst)\n",
                "        os.symlink(sam3_pt, dst)\n",
                "        print(\"âœ… linked\", dst, \"->\", sam3_pt)\n",
                "    except OSError as e:\n",
                "        print(\"âŒ symlink failed:\", dst, e)\n",
                "\n",
                "print(\"âœ… Setup complete\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Backend â€“ start FastAPI on port 8000\n",
                "import subprocess, time, requests\n",
                "\n",
                "%cd /content/vtrack-ai-studio/backend\n",
                "!pkill -f uvicorn || true\n",
                "time.sleep(2)\n",
                "\n",
                "proc = subprocess.Popen(\n",
                "    [\"uvicorn\", \"server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"],\n",
                ")\n",
                "print(f\"ðŸš€ Backend PID: {proc.pid}\")\n",
                "\n",
                "# Health check with retries\n",
                "for i in range(15):\n",
                "    try:\n",
                "        r = requests.get(\"http://localhost:8000/api/health\", timeout=5)\n",
                "        print(\"âœ… Backend health:\", r.json())\n",
                "        break\n",
                "    except Exception as e:\n",
                "        print(f\"â³ Backend not ready yet ({i+1}/15): {e}\")\n",
                "        time.sleep(3)\n",
                "else:\n",
                "    print(\"âŒ Backend failed to start, check logs above.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Frontend (Vite) â€“ runs dev server on port 4173 and prints a public URL via cloudflared\n",
                "import subprocess, textwrap, time\n",
                "\n",
                "bash_cmd = textwrap.dedent(\"\"\"\n",
                "  set -e\n",
                "  cd /content/vtrack-ai-studio\n",
                "\n",
                "  export NVM_DIR=\"$HOME/.nvm\"\n",
                "  [ -s \"$NVM_DIR/nvm.sh\" ] && . \"$NVM_DIR/nvm.sh\"\n",
                "  nvm use 18\n",
                "\n",
                "  echo 'VITE_API_URL=http://localhost:8000' > .env\n",
                "\n",
                "  echo \"NODE VERSION:\"; node -v\n",
                "  echo \"NPM VERSION:\"; npm -v\n",
                "\n",
                "  npm install\n",
                "  nohup npm run dev -- --host 0.0.0.0 --port 4173 > vite.log 2>&1 &\n",
                "\"\"\")\n",
                "\n",
                "print(\"ðŸš€ Starting Vite dev server on port 4173...\")\n",
                "subprocess.run([\"bash\", \"-lc\", bash_cmd])\n",
                "\n",
                "# Cloudflare tunnel for UI (no ngrok/localtunnel)\n",
                "!pip install -q cloudflared\n",
                "import time\n",
                "!pkill cloudflared || true\n",
                "!nohup cloudflared tunnel --url http://localhost:4173 > cloudflared_front.log 2>&1 &\n",
                "time.sleep(10)\n",
                "!grep -o 'https://[^ ]*\\\\.trycloudflare\\\\.com' cloudflared_front.log || echo \"No Cloudflare URL yet\"\n",
                "print(\"\\nðŸ“¡ Copy this URL and open in your browser â€“ it is the VTrackAI Studio UI.\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}