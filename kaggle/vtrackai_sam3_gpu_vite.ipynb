{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ”¥ VTrackAI Studio - Kaggle E2E GPU Setup\n",
                "\n",
                "**Prerequisites:**\n",
                "1. Settings â†’ Accelerator â†’ **GPU P100** or **T4 x2**\n",
                "2. Add-ons â†’ Secrets â†’ Add `HF_TOKEN` (from huggingface.co/settings/tokens)\n",
                "3. Enable **Internet** in the sidebar\n",
                "4. Run all cells (Ctrl+Shift+Enter)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "_kg_hide-output": true,
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "# CELL 1: SETUP (Run once per session, ~3-5 min)\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "import torch\n",
                "import os\n",
                "import sys\n",
                "import subprocess\n",
                "\n",
                "BASE_DIR = \"/kaggle/working\"\n",
                "os.chdir(BASE_DIR)\n",
                "\n",
                "# GPU Check\n",
                "print(\"=\"*60)\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"âœ… GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"ğŸ“Š VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
                "else:\n",
                "    print(\"âŒ NO GPU! Go to Settings â†’ Accelerator â†’ GPU P100 or T4\")\n",
                "    sys.exit(1)\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Clean start\n",
                "subprocess.run([\"rm\", \"-rf\", f\"{BASE_DIR}/vtrack-ai-studio\"])\n",
                "\n",
                "# Install dependencies\n",
                "print(\"\\nğŸ“¦ Installing dependencies...\")\n",
                "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch\", \"torchvision\", \"--index-url\", \"https://download.pytorch.org/whl/cu121\"])\n",
                "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"fastapi\", \"uvicorn[standard]\", \"python-multipart\", \"huggingface_hub\", \"requests\", \"decord\"])\n",
                "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numpy==1.26.4\"])\n",
                "\n",
                "# Node.js 18 via nodeenv\n",
                "print(\"\\nğŸ“¦ Installing Node.js 18...\")\n",
                "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"nodeenv\"])\n",
                "subprocess.run([\"nodeenv\", \"--node=18.20.0\", f\"{BASE_DIR}/node_env\", \"--force\", \"-q\"])\n",
                "\n",
                "NODE_BIN = f\"{BASE_DIR}/node_env/bin\"\n",
                "os.environ[\"PATH\"] = f\"{NODE_BIN}:{os.environ['PATH']}\"\n",
                "\n",
                "subprocess.run([f\"{NODE_BIN}/node\", \"--version\"])\n",
                "subprocess.run([f\"{NODE_BIN}/npm\", \"--version\"])\n",
                "\n",
                "# Install localtunnel\n",
                "print(\"\\nğŸ“¦ Installing localtunnel...\")\n",
                "subprocess.run([f\"{NODE_BIN}/npm\", \"install\", \"-g\", \"localtunnel\", \"--silent\"])\n",
                "\n",
                "# Clone VTrackAI\n",
                "print(\"\\nğŸ“¦ Cloning VTrackAI...\")\n",
                "subprocess.run([\"git\", \"clone\", \"-q\", \"https://github.com/Amitro123/vtrack-ai-studio\", f\"{BASE_DIR}/vtrack-ai-studio\"])\n",
                "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", f\"{BASE_DIR}/vtrack-ai-studio/backend/requirements.txt\", \"-q\"], stderr=subprocess.DEVNULL)\n",
                "\n",
                "# Clone SAM3 INTO backend/sam3 (where server.py expects it)\n",
                "print(\"\\nğŸ“¦ Cloning SAM3 into backend/sam3...\")\n",
                "BACKEND_DIR = f\"{BASE_DIR}/vtrack-ai-studio/backend\"\n",
                "os.chdir(BACKEND_DIR)\n",
                "subprocess.run([\"rm\", \"-rf\", \"./sam3\"])\n",
                "subprocess.run([\"git\", \"clone\", \"-q\", \"https://github.com/facebookresearch/sam3\", \"./sam3\"])\n",
                "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \"./sam3\", \"-q\"], stderr=subprocess.DEVNULL)\n",
                "print(\"âœ… SAM3 installed in backend/sam3\")\n",
                "\n",
                "# HuggingFace login + checkpoint\n",
                "print(\"\\nğŸ” Downloading SAM3 checkpoint...\")\n",
                "from kaggle_secrets import UserSecretsClient\n",
                "from huggingface_hub import login, hf_hub_download\n",
                "\n",
                "user_secrets = UserSecretsClient()\n",
                "HF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\n",
                "login(token=HF_TOKEN, add_to_git_credential=False)\n",
                "\n",
                "checkpoint_dir = f\"{BACKEND_DIR}/checkpoints/sam3\"\n",
                "checkpoints_subdir = f\"{checkpoint_dir}/checkpoints\"\n",
                "os.makedirs(checkpoint_dir, exist_ok=True)\n",
                "os.makedirs(checkpoints_subdir, exist_ok=True)\n",
                "\n",
                "checkpoint_path = hf_hub_download(\n",
                "    repo_id=\"facebook/sam3\",\n",
                "    filename=\"sam3.pt\",\n",
                "    local_dir=checkpoint_dir,\n",
                "    token=HF_TOKEN,\n",
                ")\n",
                "print(f\"âœ… Downloaded: {checkpoint_path}\")\n",
                "\n",
                "# Create symlinks\n",
                "sam3_pt = f\"{checkpoint_dir}/sam3.pt\"\n",
                "symlinks = [\n",
                "    f\"{checkpoint_dir}/sam3_hiera_large.pt\",\n",
                "    f\"{checkpoints_subdir}/sam3_hiera_tiny.pt\",\n",
                "    f\"{checkpoints_subdir}/sam3_hiera_large.pt\",\n",
                "]\n",
                "\n",
                "for dst in symlinks:\n",
                "    try:\n",
                "        if os.path.islink(dst) or os.path.exists(dst):\n",
                "            os.remove(dst)\n",
                "        os.symlink(sam3_pt, dst)\n",
                "        print(f\"âœ… Symlink: {os.path.basename(dst)}\")\n",
                "    except OSError as e:\n",
                "        print(f\"âŒ Symlink failed: {dst} - {e}\")\n",
                "\n",
                "os.chdir(BASE_DIR)\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"âœ… SETUP COMPLETE! Run Cell 2 to start backend.\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "# CELL 2: START BACKEND + TUNNEL\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "import subprocess\n",
                "import time\n",
                "import requests\n",
                "import os\n",
                "import re\n",
                "import urllib.request\n",
                "\n",
                "BASE_DIR = \"/kaggle/working\"\n",
                "BACKEND_DIR = f\"{BASE_DIR}/vtrack-ai-studio/backend\"\n",
                "NODE_BIN = f\"{BASE_DIR}/node_env/bin\"\n",
                "os.environ[\"PATH\"] = f\"{NODE_BIN}:{os.environ['PATH']}\"\n",
                "\n",
                "# Get public IP\n",
                "print(\"ğŸ” Getting public IP...\")\n",
                "try:\n",
                "    PUBLIC_IP = urllib.request.urlopen('https://api.ipify.org').read().decode('utf8')\n",
                "    print(f\"âœ… Public IP: {PUBLIC_IP}\")\n",
                "except Exception:\n",
                "    PUBLIC_IP = \"(could not detect)\"\n",
                "\n",
                "# Kill existing\n",
                "subprocess.run([\"pkill\", \"-9\", \"-f\", \"uvicorn\"], stderr=subprocess.DEVNULL)\n",
                "subprocess.run([\"pkill\", \"-9\", \"-f\", \"lt\"], stderr=subprocess.DEVNULL)\n",
                "time.sleep(2)\n",
                "\n",
                "# Verify SAM3\n",
                "print(\"\\nğŸ” Checking SAM3...\")\n",
                "print(f\"   SAM3: {'âœ…' if os.path.exists(f'{BACKEND_DIR}/sam3') else 'âŒ'} found\")\n",
                "print(f\"   Checkpoint: {'âœ…' if os.path.exists(f'{BACKEND_DIR}/checkpoints/sam3/sam3.pt') else 'âŒ'} found\")\n",
                "\n",
                "# Start backend\n",
                "print(\"\\nğŸš€ Starting backend...\")\n",
                "log_file = open(f\"{BASE_DIR}/backend.log\", \"w\")\n",
                "proc = subprocess.Popen(\n",
                "    [\"uvicorn\", \"server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"],\n",
                "    stdout=log_file,\n",
                "    stderr=subprocess.STDOUT,\n",
                "    cwd=BACKEND_DIR,\n",
                ")\n",
                "\n",
                "# Wait for backend\n",
                "backend_ready = False\n",
                "for i in range(30):\n",
                "    if proc.poll() is not None:\n",
                "        print(\"âŒ Backend crashed!\")\n",
                "        with open(f\"{BASE_DIR}/backend.log\") as f:\n",
                "            print(f.read()[-2000:])\n",
                "        break\n",
                "    try:\n",
                "        r = requests.get(\"http://localhost:8000/api/health\", timeout=3)\n",
                "        health = r.json()\n",
                "        print(f\"âœ… Backend running - SAM3: {'âœ…' if health.get('sam3_available') else 'âŒ'}\")\n",
                "        backend_ready = True\n",
                "        break\n",
                "    except Exception:\n",
                "        print(f\"â³ Waiting... ({i+1}/30)\")\n",
                "        time.sleep(2)\n",
                "\n",
                "if backend_ready:\n",
                "    # Start tunnel\n",
                "    print(\"\\nğŸŒ Creating backend tunnel...\")\n",
                "    tunnel_log = open(f\"{BASE_DIR}/backend_tunnel.log\", \"w\")\n",
                "    subprocess.Popen([f\"{NODE_BIN}/lt\", \"--port\", \"8000\"], stdout=tunnel_log, stderr=subprocess.STDOUT)\n",
                "    time.sleep(8)\n",
                "    \n",
                "    with open(f\"{BASE_DIR}/backend_tunnel.log\") as f:\n",
                "        urls = re.findall(r'https://[\\w-]+\\.loca\\.lt', f.read())\n",
                "    \n",
                "    if urls:\n",
                "        with open(f\"{BASE_DIR}/backend_url.txt\", \"w\") as f:\n",
                "            f.write(urls[0])\n",
                "        print(f\"\\n\" + \"=\"*60)\n",
                "        print(f\"âœ… Backend: {urls[0]}\")\n",
                "        print(f\"ğŸ”‘ Password: {PUBLIC_IP}\")\n",
                "        print(\"=\"*60)\n",
                "        print(\"\\nâœ… Run Cell 3 to warm up SAM3.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "# CELL 3: SAM3 WARM-UP (Pre-compute cache)\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "import requests\n",
                "import time\n",
                "\n",
                "print(\"ğŸ”¥ Warming up SAM3 model...\")\n",
                "print(\"   This may take 30-60 seconds on first run.\")\n",
                "\n",
                "try:\n",
                "    # Call warmup endpoint\n",
                "    r = requests.post(\"http://localhost:8000/api/warmup\", timeout=120)\n",
                "    result = r.json()\n",
                "    print(f\"\\nâœ… Warm-up result: {result}\")\n",
                "except Exception as e:\n",
                "    print(f\"âŒ Warm-up failed: {e}\")\n",
                "\n",
                "# Final health check\n",
                "print(\"\\nğŸ“Š Final health check:\")\n",
                "health = requests.get(\"http://localhost:8000/api/health\").json()\n",
                "print(f\"   SAM3 Available: {health.get('sam3_available')}\")\n",
                "print(f\"   SAM3 Initialized: {health.get('sam3_initialized')}\")\n",
                "print(f\"   Device: {health.get('device')}\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"âœ… SAM3 is ready! Run Cell 4 to start frontend.\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "# CELL 4: START FRONTEND + TUNNEL\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "import subprocess\n",
                "import time\n",
                "import os\n",
                "import re\n",
                "import urllib.request\n",
                "\n",
                "BASE_DIR = \"/kaggle/working\"\n",
                "NODE_BIN = f\"{BASE_DIR}/node_env/bin\"\n",
                "os.environ[\"PATH\"] = f\"{NODE_BIN}:{os.environ['PATH']}\"\n",
                "\n",
                "try:\n",
                "    PUBLIC_IP = urllib.request.urlopen('https://api.ipify.org').read().decode('utf8')\n",
                "except Exception:\n",
                "    PUBLIC_IP = \"(could not detect)\"\n",
                "\n",
                "# Read backend URL\n",
                "try:\n",
                "    with open(f\"{BASE_DIR}/backend_url.txt\") as f:\n",
                "        BACKEND_URL = f.read().strip()\n",
                "    print(f\"ğŸ“¡ Backend: {BACKEND_URL}\")\n",
                "except Exception:\n",
                "    BACKEND_URL = \"http://localhost:8000\"\n",
                "    print(\"âš ï¸ Using localhost backend\")\n",
                "\n",
                "# Kill existing frontend\n",
                "subprocess.run([\"pkill\", \"-9\", \"-f\", \"vite\"], stderr=subprocess.DEVNULL)\n",
                "time.sleep(1)\n",
                "\n",
                "# Install frontend\n",
                "print(\"\\nğŸš€ Installing frontend...\")\n",
                "os.chdir(f\"{BASE_DIR}/vtrack-ai-studio\")\n",
                "\n",
                "with open(\".env\", \"w\") as f:\n",
                "    f.write(f\"VITE_API_URL={BACKEND_URL}\\n\")\n",
                "\n",
                "subprocess.run([f\"{NODE_BIN}/npm\", \"install\", \"--silent\"], stderr=subprocess.DEVNULL)\n",
                "\n",
                "# Start Vite\n",
                "print(\"ğŸš€ Starting frontend...\")\n",
                "vite_log = open(f\"{BASE_DIR}/vite.log\", \"w\")\n",
                "subprocess.Popen(\n",
                "    [f\"{NODE_BIN}/npm\", \"run\", \"dev\", \"--\", \"--host\", \"0.0.0.0\", \"--port\", \"4173\"],\n",
                "    stdout=vite_log, stderr=subprocess.STDOUT,\n",
                "    cwd=f\"{BASE_DIR}/vtrack-ai-studio\"\n",
                ")\n",
                "time.sleep(15)\n",
                "\n",
                "# Start tunnel\n",
                "print(\"\\nğŸŒ Creating frontend tunnel...\")\n",
                "tunnel_log = open(f\"{BASE_DIR}/frontend_tunnel.log\", \"w\")\n",
                "subprocess.Popen([f\"{NODE_BIN}/lt\", \"--port\", \"4173\"], stdout=tunnel_log, stderr=subprocess.STDOUT)\n",
                "time.sleep(8)\n",
                "\n",
                "with open(f\"{BASE_DIR}/frontend_tunnel.log\") as f:\n",
                "    urls = re.findall(r'https://[\\w-]+\\.loca\\.lt', f.read())\n",
                "\n",
                "if urls:\n",
                "    print(\"\\n\" + \"=\"*60)\n",
                "    print(\"ğŸ‰ VTrackAI Studio is LIVE!\")\n",
                "    print(f\"\\n   ğŸ‘‰ FRONTEND: {urls[0]}\")\n",
                "    print(f\"   ğŸ“¡ BACKEND:  {BACKEND_URL}\")\n",
                "    print(f\"\\n   ğŸ”‘ PASSWORD: {PUBLIC_IP}\")\n",
                "    print(\"\\n   âš ï¸ Enter password on BOTH URLs!\")\n",
                "    print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "# CELL 5: GET URLS (Run if needed)\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "import re\n",
                "import urllib.request\n",
                "\n",
                "BASE_DIR = \"/kaggle/working\"\n",
                "try:\n",
                "    PUBLIC_IP = urllib.request.urlopen('https://api.ipify.org').read().decode('utf8')\n",
                "except:\n",
                "    PUBLIC_IP = \"unknown\"\n",
                "\n",
                "print(\"=\" * 60)\n",
                "try:\n",
                "    with open(f\"{BASE_DIR}/backend_tunnel.log\") as f:\n",
                "        urls = re.findall(r'https://[\\w-]+\\.loca\\.lt', f.read())\n",
                "        if urls: print(f\"ğŸ“¡ BACKEND: {urls[0]}\")\n",
                "except: pass\n",
                "\n",
                "try:\n",
                "    with open(f\"{BASE_DIR}/frontend_tunnel.log\") as f:\n",
                "        urls = re.findall(r'https://[\\w-]+\\.loca\\.lt', f.read())\n",
                "        if urls: print(f\"ğŸ‘‰ FRONTEND: {urls[0]}\")\n",
                "except: pass\n",
                "\n",
                "print(f\"\\nğŸ”‘ PASSWORD: {PUBLIC_IP}\")\n",
                "print(\"=\" * 60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "# CELL 6: DEBUG LOGS\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "import os\n",
                "import subprocess\n",
                "BASE_DIR = \"/kaggle/working\"\n",
                "\n",
                "print(\"=== SAM3 Check ===\")\n",
                "sam3_path = f\"{BASE_DIR}/vtrack-ai-studio/backend/sam3\"\n",
                "print(f\"Exists: {os.path.exists(sam3_path)}\")\n",
                "\n",
                "print(\"\\n=== Checkpoints ===\")\n",
                "ckpt_dir = f\"{BASE_DIR}/vtrack-ai-studio/backend/checkpoints/sam3\"\n",
                "if os.path.exists(ckpt_dir):\n",
                "    for f in os.listdir(ckpt_dir):\n",
                "        path = os.path.join(ckpt_dir, f)\n",
                "        if os.path.islink(path):\n",
                "            print(f\"  {f} -> symlink\")\n",
                "        elif os.path.isfile(path):\n",
                "            print(f\"  {f} ({os.path.getsize(path)/1e6:.1f}MB)\")\n",
                "\n",
                "print(\"\\n=== Backend Log (last 30 lines) ===\")\n",
                "try:\n",
                "    with open(f\"{BASE_DIR}/backend.log\") as f:\n",
                "        print(\"\".join(f.readlines()[-30:]))\n",
                "except: print(\"No log\")\n",
                "\n",
                "print(\"\\n=== Processes ===\")\n",
                "result = subprocess.run([\"ps\", \"aux\"], capture_output=True, text=True)\n",
                "for line in result.stdout.split(\"\\n\"):\n",
                "    if any(x in line for x in [\"uvicorn\", \"node\", \"lt\"]) and \"grep\" not in line:\n",
                "        print(line)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "# CELL 7: CLEANUP\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "import subprocess\n",
                "print(\"ğŸ§¹ Cleaning up...\")\n",
                "subprocess.run([\"pkill\", \"-9\", \"-f\", \"uvicorn\"], stderr=subprocess.DEVNULL)\n",
                "subprocess.run([\"pkill\", \"-9\", \"-f\", \"node\"], stderr=subprocess.DEVNULL)\n",
                "subprocess.run([\"pkill\", \"-9\", \"-f\", \"lt\"], stderr=subprocess.DEVNULL)\n",
                "print(\"âœ… Done\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "kaggle": {
            "accelerator": "gpu",
            "dataSources": [],
            "isGpuEnabled": true,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}