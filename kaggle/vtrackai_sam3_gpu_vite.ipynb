{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ”¥ VTrackAI Studio - Kaggle E2E GPU Setup\n",
                "\n",
                "**Prerequisites:**\n",
                "1. Settings â†’ Accelerator â†’ **GPU P100** or **T4 x2**\n",
                "2. Add-ons â†’ Secrets â†’ Add `HF_TOKEN` (from huggingface.co/settings/tokens)\n",
                "3. Enable **Internet** in the sidebar\n",
                "4. Run all cells (Ctrl+Shift+Enter)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "_kg_hide-output": true,
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "# CELL 1: SETUP (Run once per session, ~3-5 min)\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "import torch\n",
                "import os\n",
                "import sys\n",
                "import subprocess\n",
                "\n",
                "# Define base directory (Kaggle uses /kaggle/working)\n",
                "BASE_DIR = \"/kaggle/working\"\n",
                "os.chdir(BASE_DIR)\n",
                "\n",
                "# GPU Check\n",
                "print(\"=\"*60)\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"âœ… GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"ğŸ“Š VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
                "else:\n",
                "    print(\"âŒ NO GPU! Go to Settings â†’ Accelerator â†’ GPU P100 or T4\")\n",
                "    sys.exit(1)\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Clean start\n",
                "subprocess.run([\"rm\", \"-rf\", f\"{BASE_DIR}/sam3\", f\"{BASE_DIR}/vtrack-ai-studio\"])\n",
                "\n",
                "# Install dependencies\n",
                "print(\"\\nğŸ“¦ Installing dependencies...\")\n",
                "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch\", \"torchvision\", \"--index-url\", \"https://download.pytorch.org/whl/cu121\"])\n",
                "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"fastapi\", \"uvicorn[standard]\", \"python-multipart\", \"huggingface_hub\", \"requests\", \"decord\"])\n",
                "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"numpy==1.26.4\"])\n",
                "\n",
                "# Node.js 18 via nodeenv (nvm doesn't work well on Kaggle)\n",
                "print(\"\\nğŸ“¦ Installing Node.js 18...\")\n",
                "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"nodeenv\"])\n",
                "subprocess.run([\"nodeenv\", \"--node=18.20.0\", f\"{BASE_DIR}/node_env\", \"--force\", \"-q\"])\n",
                "\n",
                "# Set up node path\n",
                "NODE_BIN = f\"{BASE_DIR}/node_env/bin\"\n",
                "os.environ[\"PATH\"] = f\"{NODE_BIN}:{os.environ['PATH']}\"\n",
                "\n",
                "# Verify node installation\n",
                "subprocess.run([f\"{NODE_BIN}/node\", \"--version\"])\n",
                "subprocess.run([f\"{NODE_BIN}/npm\", \"--version\"])\n",
                "\n",
                "# Install localtunnel globally (free, no auth required)\n",
                "print(\"\\nğŸ“¦ Installing localtunnel...\")\n",
                "subprocess.run([f\"{NODE_BIN}/npm\", \"install\", \"-g\", \"localtunnel\", \"--silent\"])\n",
                "\n",
                "# Clone SAM3\n",
                "print(\"\\nğŸ“¦ Cloning SAM3...\")\n",
                "subprocess.run([\"git\", \"clone\", \"-q\", \"https://github.com/facebookresearch/sam3\", f\"{BASE_DIR}/sam3\"])\n",
                "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", f\"{BASE_DIR}/sam3\", \"-q\"], stderr=subprocess.DEVNULL)\n",
                "\n",
                "# Clone VTrackAI\n",
                "print(\"ğŸ“¦ Cloning VTrackAI...\")\n",
                "subprocess.run([\"git\", \"clone\", \"-q\", \"https://github.com/Amitro123/vtrack-ai-studio\", f\"{BASE_DIR}/vtrack-ai-studio\"])\n",
                "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", f\"{BASE_DIR}/vtrack-ai-studio/backend/requirements.txt\", \"-q\"], stderr=subprocess.DEVNULL)\n",
                "\n",
                "# HuggingFace login + checkpoint\n",
                "print(\"\\nğŸ” Downloading SAM3 checkpoint...\")\n",
                "from kaggle_secrets import UserSecretsClient\n",
                "from huggingface_hub import login, hf_hub_download\n",
                "\n",
                "user_secrets = UserSecretsClient()\n",
                "HF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\n",
                "login(token=HF_TOKEN, add_to_git_credential=False)\n",
                "\n",
                "checkpoint_dir = f\"{BASE_DIR}/vtrack-ai-studio/backend/checkpoints/sam3\"\n",
                "os.makedirs(checkpoint_dir, exist_ok=True)\n",
                "checkpoint_path = hf_hub_download(\n",
                "    repo_id=\"facebook/sam3\",\n",
                "    filename=\"sam3.pt\",\n",
                "    local_dir=checkpoint_dir,\n",
                "    token=HF_TOKEN,\n",
                ")\n",
                "\n",
                "# Create symlinks\n",
                "sam3_pt = f\"{checkpoint_dir}/sam3.pt\"\n",
                "symlink_dst = f\"{checkpoint_dir}/sam3_hiera_large.pt\"\n",
                "if os.path.exists(symlink_dst):\n",
                "    os.remove(symlink_dst)\n",
                "os.symlink(sam3_pt, symlink_dst)\n",
                "\n",
                "print(f\"âœ… Checkpoint ready: {checkpoint_path}\")\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"âœ… SETUP COMPLETE! Run Cell 2 to start backend.\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "# CELL 2: START BACKEND (FastAPI on port 8000)\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "import subprocess\n",
                "import time\n",
                "import requests\n",
                "import os\n",
                "\n",
                "BASE_DIR = \"/kaggle/working\"\n",
                "\n",
                "# Kill any existing backend\n",
                "subprocess.run([\"pkill\", \"-9\", \"-f\", \"uvicorn\"], stderr=subprocess.DEVNULL)\n",
                "time.sleep(2)\n",
                "\n",
                "# Start backend in background\n",
                "print(\"ğŸš€ Starting FastAPI backend...\")\n",
                "log_file = open(f\"{BASE_DIR}/backend.log\", \"w\")\n",
                "proc = subprocess.Popen(\n",
                "    [\"uvicorn\", \"server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"],\n",
                "    stdout=log_file,\n",
                "    stderr=subprocess.STDOUT,\n",
                "    cwd=f\"{BASE_DIR}/vtrack-ai-studio/backend\",\n",
                ")\n",
                "\n",
                "# Wait for backend with retries\n",
                "for i in range(20):\n",
                "    if proc.poll() is not None:\n",
                "        print(\"âŒ Backend crashed! Logs:\")\n",
                "        with open(f\"{BASE_DIR}/backend.log\") as f:\n",
                "            print(f.read())\n",
                "        break\n",
                "    try:\n",
                "        r = requests.get(\"http://localhost:8000/api/health\", timeout=3)\n",
                "        health = r.json()\n",
                "        print(\"\\n\" + \"=\"*60)\n",
                "        print(\"âœ… Backend running on port 8000\")\n",
                "        print(f\"   SAM3: {'âœ… Available' if health.get('sam3_available') else 'âŒ Not loaded'}\")\n",
                "        print(f\"   Device: {health.get('device', 'unknown')}\")\n",
                "        print(\"=\"*60)\n",
                "        break\n",
                "    except Exception:\n",
                "        print(f\"â³ Waiting... ({i+1}/20)\")\n",
                "        time.sleep(3)\n",
                "else:\n",
                "    print(\"âŒ Backend failed to start. Logs:\")\n",
                "    with open(f\"{BASE_DIR}/backend.log\") as f:\n",
                "        print(f.read())\n",
                "\n",
                "print(\"\\nâœ… Run Cell 3 to start frontend.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "# CELL 3: START FRONTEND (Vite + localtunnel - NO AUTH REQUIRED)\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "import subprocess\n",
                "import time\n",
                "import os\n",
                "import re\n",
                "\n",
                "BASE_DIR = \"/kaggle/working\"\n",
                "NODE_BIN = f\"{BASE_DIR}/node_env/bin\"\n",
                "\n",
                "# Ensure node is in PATH\n",
                "os.environ[\"PATH\"] = f\"{NODE_BIN}:{os.environ['PATH']}\"\n",
                "\n",
                "# Install frontend dependencies\n",
                "print(\"ğŸš€ Installing frontend dependencies...\")\n",
                "os.chdir(f\"{BASE_DIR}/vtrack-ai-studio\")\n",
                "\n",
                "# Write .env file\n",
                "with open(\".env\", \"w\") as f:\n",
                "    f.write(\"VITE_API_URL=http://localhost:8000\\n\")\n",
                "\n",
                "subprocess.run([f\"{NODE_BIN}/npm\", \"install\", \"--silent\"], stderr=subprocess.DEVNULL)\n",
                "\n",
                "# Start Vite dev server in background\n",
                "print(\"ğŸš€ Starting Vite frontend...\")\n",
                "vite_log = open(f\"{BASE_DIR}/vite.log\", \"w\")\n",
                "vite_proc = subprocess.Popen(\n",
                "    [f\"{NODE_BIN}/npm\", \"run\", \"dev\", \"--\", \"--host\", \"0.0.0.0\", \"--port\", \"4173\"],\n",
                "    stdout=vite_log,\n",
                "    stderr=subprocess.STDOUT,\n",
                "    cwd=f\"{BASE_DIR}/vtrack-ai-studio\",\n",
                "    env={**os.environ}\n",
                ")\n",
                "\n",
                "# Wait for Vite to start\n",
                "print(\"â³ Waiting for Vite to start...\")\n",
                "time.sleep(15)\n",
                "\n",
                "# Start localtunnel (FREE - no auth required!)\n",
                "print(\"ğŸŒ Creating localtunnel (free, no auth required)...\")\n",
                "tunnel_log = open(f\"{BASE_DIR}/tunnel.log\", \"w\")\n",
                "tunnel_proc = subprocess.Popen(\n",
                "    [f\"{NODE_BIN}/lt\", \"--port\", \"4173\"],\n",
                "    stdout=tunnel_log,\n",
                "    stderr=subprocess.STDOUT,\n",
                "    env={**os.environ}\n",
                ")\n",
                "\n",
                "# Wait and extract URL\n",
                "time.sleep(8)\n",
                "\n",
                "# Read tunnel URL\n",
                "try:\n",
                "    with open(f\"{BASE_DIR}/tunnel.log\") as f:\n",
                "        log = f.read()\n",
                "    urls = re.findall(r'https://[\\w-]+\\.loca\\.lt', log)\n",
                "    if urls:\n",
                "        print(\"\\n\" + \"=\"*60)\n",
                "        print(\"ğŸ‰ VTrackAI Studio is LIVE!\")\n",
                "        print(f\"\\n   ğŸ‘‰ {urls[0]}\")\n",
                "        print(\"\\n   âš ï¸  Click 'Click to Continue' on the tunnel page\")\n",
                "        print(\"   (This is a localtunnel security check)\")\n",
                "        print(\"=\"*60)\n",
                "    else:\n",
                "        print(\"â³ Getting tunnel URL...\")\n",
                "        print(log)\n",
                "except Exception as e:\n",
                "    print(f\"Error reading tunnel log: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "# CELL 4: GET TUNNEL URL (Run if URL not shown above)\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "import re\n",
                "\n",
                "BASE_DIR = \"/kaggle/working\"\n",
                "\n",
                "print(\"=== Tunnel URL ===\")\n",
                "try:\n",
                "    with open(f\"{BASE_DIR}/tunnel.log\") as f:\n",
                "        log = f.read()\n",
                "    urls = re.findall(r'https://[\\w-]+\\.loca\\.lt', log)\n",
                "    if urls:\n",
                "        print(f\"\\nğŸ‘‰ {urls[0]}\\n\")\n",
                "        print(\"âš ï¸  Click 'Click to Continue' on the tunnel page\")\n",
                "    else:\n",
                "        print(\"Tunnel log:\")\n",
                "        print(log)\n",
                "except Exception:\n",
                "    print(\"No tunnel log found\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "# CELL 5: DEBUG / LOGS (Run if needed)\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "import os\n",
                "import subprocess\n",
                "\n",
                "BASE_DIR = \"/kaggle/working\"\n",
                "\n",
                "print(\"=== Backend Logs ===\")\n",
                "try:\n",
                "    with open(f\"{BASE_DIR}/backend.log\") as f:\n",
                "        lines = f.readlines()[-20:]\n",
                "        print(\"\".join(lines))\n",
                "except Exception:\n",
                "    print(\"No backend log\")\n",
                "\n",
                "print(\"\\n=== Vite Logs ===\")\n",
                "try:\n",
                "    with open(f\"{BASE_DIR}/vite.log\") as f:\n",
                "        lines = f.readlines()[-10:]\n",
                "        print(\"\".join(lines))\n",
                "except Exception:\n",
                "    print(\"No vite log\")\n",
                "\n",
                "print(\"\\n=== Tunnel Logs ===\")\n",
                "try:\n",
                "    with open(f\"{BASE_DIR}/tunnel.log\") as f:\n",
                "        print(f.read())\n",
                "except Exception:\n",
                "    print(\"No tunnel log\")\n",
                "\n",
                "print(\"\\n=== Process Status ===\")\n",
                "result = subprocess.run([\"ps\", \"aux\"], capture_output=True, text=True)\n",
                "for line in result.stdout.split(\"\\n\"):\n",
                "    if any(x in line for x in [\"uvicorn\", \"node\", \"lt\"]) and \"grep\" not in line:\n",
                "        print(line)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "# CELL 6: CLEANUP (Run when done)\n",
                "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "import subprocess\n",
                "\n",
                "print(\"ğŸ§¹ Cleaning up...\")\n",
                "\n",
                "# Kill processes\n",
                "subprocess.run([\"pkill\", \"-9\", \"-f\", \"uvicorn\"], stderr=subprocess.DEVNULL)\n",
                "subprocess.run([\"pkill\", \"-9\", \"-f\", \"node\"], stderr=subprocess.DEVNULL)\n",
                "subprocess.run([\"pkill\", \"-9\", \"-f\", \"lt\"], stderr=subprocess.DEVNULL)\n",
                "\n",
                "print(\"âœ… Cleanup complete. All services stopped.\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "kaggle": {
            "accelerator": "gpu",
            "dataSources": [],
            "isGpuEnabled": true,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}